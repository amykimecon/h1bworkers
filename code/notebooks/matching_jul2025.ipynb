{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9965ccc7",
   "metadata": {},
   "source": [
    "# July 11th Updates: Matching and Filtering H-1B and Revelio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PACKAGE/MODULE IMPORTS AND PATHS\n",
    "import duckdb as ddb\n",
    "import sys \n",
    "\n",
    "sys.path.append('../')\n",
    "from config import * \n",
    "\n",
    "# # helper functions\n",
    "# sys.path.append('02_revelio_indiv_clean/')\n",
    "# import rev_indiv_clean_helpers as help\n",
    "\n",
    "con = ddb.connect()\n",
    "\n",
    "# Importing Country Codes Crosswalk\n",
    "with open(f\"{root}/data/crosswalks/country_dict.json\", \"r\") as json_file:\n",
    "    country_cw_dict = json.load(json_file)\n",
    "\n",
    "# helper function to get standardized country name\n",
    "def get_std_country(country, dict = country_cw_dict):\n",
    "    if country is None:\n",
    "        return None \n",
    "    \n",
    "    if country in dict.keys():\n",
    "        return dict[country]\n",
    "    \n",
    "    if country in dict.values():\n",
    "        return country \n",
    "    \n",
    "    return \"No Country Match\"\n",
    "\n",
    "con.create_function(\"get_std_country\", lambda x: get_std_country(x), ['VARCHAR'], 'VARCHAR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16878855, 19)\n",
      "(23850622, 19)\n",
      "(32457059, 19)\n",
      "(39418941, 19)\n",
      "(47525355, 19)\n",
      "(55425986, 19)\n",
      "(62847741, 19)\n",
      "(71625007, 19)\n",
      "(79574137, 19)\n"
     ]
    },
    {
     "ename": "IOException",
     "evalue": "IO Error: No files found that match the pattern \"/Users/amykim/Princeton Dropbox/Amy Kim/h1bworkers/data/int/rev_names_nametrace_jul8.parquet\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Importing Name x Country Matches\u001b[39;00m\n\u001b[1;32m     25\u001b[0m nanats \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/int/name2nat_revelio/rev_names_withnat_jun26.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m nts \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/int/rev_names_nametrace_jul8.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Importing User x Position-level Data\u001b[39;00m\n\u001b[1;32m     29\u001b[0m merged_pos \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/int/rev_merge_mar20.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: No files found that match the pattern \"/Users/amykim/Princeton Dropbox/Amy Kim/h1bworkers/data/int/rev_names_nametrace_jul8.parquet\""
     ]
    }
   ],
   "source": [
    "### RAW DATA IMPORT\n",
    "## duplicate rcids (companies that appear more than once in linkedin data)\n",
    "dup_rcids = con.read_csv(f\"{root}/data/int/dup_rcids_mar20.csv\")\n",
    "\n",
    "## matched company data from R\n",
    "rmerge = con.read_csv(f\"{root}/data/int/good_match_ids_mar20.csv\")\n",
    "\n",
    "## raw FOIA bloomberg data\n",
    "foia_raw_file = con.read_csv(f\"{root}/data/raw/foia_bloomberg/foia_bloomberg_all.csv\")\n",
    "\n",
    "## joining raw FOIA data with merged data to get foia_ids in raw foia data\n",
    "foia_with_ids = con.sql(\"SELECT *, CASE WHEN matched IS NULL THEN 0 ELSE matched END AS matchind FROM ((SELECT * FROM foia_raw_file WHERE NOT FEIN = '(b)(3) (b)(6) (b)(7)(c)') AS a LEFT JOIN (SELECT lottery_year, FEIN, foia_id, 1 AS matched FROM rmerge GROUP BY lottery_year, FEIN, foia_id) AS b ON a.lottery_year = b.lottery_year AND a.FEIN = b.FEIN)\")\n",
    "\n",
    "# Importing User x Education-level Data (From WRDS Server)\n",
    "rev_raw = con.read_parquet(f\"{wrds_out}/rev_user_merge0.parquet\")\n",
    "\n",
    "for j in range(1,10):\n",
    "    rev_raw = con.sql(f\"SELECT * FROM rev_raw UNION ALL SELECT * FROM '{wrds_out}/rev_user_merge{j}.parquet'\")\n",
    "    print(rev_raw.shape)\n",
    "\n",
    "# Importing Institution x Country Matches\n",
    "inst_country_cw = con.read_parquet(f\"{root}/data/int/rev_inst_countries_jun30.parquet\")\n",
    "\n",
    "# Importing Name x Country Matches\n",
    "nanats = con.read_parquet(f\"{root}/data/int/name2nat_revelio/rev_names_withnat_jun26.parquet\")\n",
    "nts = con.read_parquet(f'{root}/data/int/rev_names_nametrace_jul8.parquet')\n",
    "\n",
    "# Importing User x Position-level Data\n",
    "merged_pos = con.read_parquet(f\"{root}/data/int/rev_merge_mar20.parquet\")\n",
    "#occ_cw = con.read_csv(f\"{root}/data/crosswalks/rev_occ_to_foia_freq.csv\")\n",
    "\n",
    "### CLEANED DATA\n",
    "## company crosswalk\n",
    "company_cw = con.read_parquet(f\"{root}/data/int/company_merge_sample_jun30.parquet\")\n",
    "\n",
    "## revelio individual user x country cleaned data\n",
    "rev_users = con.read_parquet(f'{root}/data/int/rev_users_clean_jun30.parquet')\n",
    "\n",
    "## revelio user x position history data\n",
    "rev_positionhist = con.read_parquet(f'{root}/data/wrds/wrds_out/rev_user_positionhist_jul2.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2846c094",
   "metadata": {},
   "source": [
    "## 'Left-Hand Side': H-1B Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cb1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW H-1B APPLICATIONS\n",
    "\n",
    "# 1. total\n",
    "# 2. multiple reg\n",
    "# 3. small emp (final samp)\n",
    "\n",
    "# 4. further cuts: suff diversity, 5. repeated lottery tries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef62ef1",
   "metadata": {},
   "source": [
    "## 'Right-Hand Side': LinkedIn Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96189f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
